---
# title: "A Bayesian approach to decision making in Anything"
# subtitle: "An open source R package"
# author: "Audrey Yeo"
# institute: ""
format: 
 revealjs:
    code-fold: false
    width: 1280
    height: 720
    chalkboard: true
preload-iframes: true
editor: 
  markdown: 
    wrap: 72
csl: apa-single-spaced.csl
footer: "Audrey Yeo"
---

```{r, echo = FALSE, warning = FALSE}
# Load relevant packages
library(testthat)
library(tidyverse)
library(flextable)
library(ggplot2)
library(float)
library(utils)
library(kableExtra)
library(formattable)
library(ggfun)
library(hexSticker)
library(lattice)
library(devtools)
devtools::install_github("https://github.com/Genentech/phase1b", force = TRUE)
library(phase1b)
library(cowplot)
```

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.pos = 'H')
```

```{r}
# Mode
Mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}
```


```{r}
# | fig-alt : "This hexagon is the R sticker for phase1b R package. It has a bright purple background, light orange border and the title is in fuschia. The graph in the middle is a CDF distribution in dots that changes from red dots to green dots to indicate a stop to go decision"
control = 0.6
thetaT_low = 0.6
result <- predprob(
  x = 16, n = 23, Nmax = 40, p = control, thetaT = thetaT_low,
  parE = c(0.6, 0.4)
)

thetaT_high = 0.9
result_high_thetaT <- predprob(
  x = 16, n = 23, Nmax = 40, p = control, thetaT = thetaT_high,
  parE = c(0.6, 0.4)
)
data = rbind(result$table, result_high_thetaT$table)

data$thetaT = c(rep("60%", 18), rep("90%", 18))
df_thetaTlow <- data %>% filter(thetaT == "60%") 
df_thetaTlow$cumul_x <- df_thetaTlow$counts + 16

df_thetaThigh <- data %>% filter(thetaT == "90%") 
df_thetaThigh$cumul_x <- df_thetaThigh$counts + 16
```


# A Bayesian approach to decision making in drug and career discovery  {background-iframe="lego-loader/dist/index.html"} 
\
\
**Audrey Yeo**
\
AMIDD cohort - University of Basel, Switzerland, Winter 2024

# Agenda

- Discipline of Statistics & Bayesian Statistics 
- How I am learning Statistics
- The importance of Statistical Intuition 
- Career in Statistics : the phase1b R package

#

1. `Opinions do not reflect employer and based only on Historical Information : )`

2. `This presentation has ALT text and as much as possible, uses colour-blind friendly palettes`

3. `Code for this Quarto-rendered .html will also be shared`


# Discipline of Statistics{.smaller}

- Theory explaining phenomenon. 

- Parametric vs Non-Parametric "explanation".

- Frequentist vs Bayesian Paradigm.

# Bayesian Statistics 
<!-- An example of Parameter (when we use distributions) : -->
<!-- - an event x has a binary outcome : Yes or No, Cure or Non-cure, Green or Black -->
<!-- (if there are more than 2 outcomes, it is a multinomial distribution) -->
- Degree of belief vs Long run frequency of events

- Model the distribution of the updated reality based on data and priors 

- Some keywords : Cumulative distribution function (CDF), probability mass/density function (pmf/pdf), Likelihood function (observation pmf/pdf)

# How I am learning Statistics{.smaller}

- youtube videos, wikipedia
- big picture understanding then ...
- going step by step, leaving no gaps
- it's ok to be "slow", this may be more efficient
- helping others
- knowing that success and failure are both imposters

# My Journey so far{.smaller}
\
\

::: columns
::: {.column width="22%"}       
```{r}
knitr::include_graphics("images/sydneyuni.jpeg", error = FALSE)
```
:::
::: {.column width="20%"}
```{r}
knitr::include_graphics("images/rch.jpg", error = FALSE)
```
:::
::: {.column width="15%"}
```{r}
knitr::include_graphics("images/hex3.png", error = FALSE)
```
:::
::: {.column width="17%"}
```{r}
knitr::include_graphics("images/openstatsware-hex.svg", error = FALSE)
```
:::
::: {.column width="20%"}
```{r}
knitr::include_graphics("images/roche1.jpg", error = FALSE)
```
:::
:::

<!-- # Journey at Roche{.smaller} -->

<!-- ```{r} -->
<!-- #| layout-ncol: 3 -->
<!-- #| fig-width: 0.25 -->
<!-- #| fig-height: 0.5 -->
<!-- #| fig-align: center -->
<!-- knitr::include_graphics("images/hex3.png", error = FALSE) -->
<!-- knitr::include_graphics("images/PSI_Stand.jpg", error = FALSE) -->
<!-- ``` -->



<!-- -   6 months into starting at Roche, I have my first presentation in decision gating -->
<!--     -   skills : R programming, writing functions, version control (GitLab, GitHub), presentation and communication -->
<!-- -   started `phase1b` in July 2023 -->
<!-- -   `phase1b`'s first external tour at PSI and useR! in 2024 -->
<!-- -   BSci/ M Nursing double-degree program at University of Sydney -->
<!-- -   Registered Nurse  -->
<!--     - St Vincents Hospital, Melbourne (Neurosurgery, Oncology, Palliative Care) -->
<!--     - Peter MacCallum Cancer Center, Melbourne (Acute Care, Clinics) -->
<!--     - Royal Children's Hospital (COVID ICU, NICU) -->
<!-- - World Health Organisation - Economic Evaluation (9 mo) -->
<!-- - Swiss TPH (3 mo) -->
<!-- - Zurich Insurance Company (Digital Transformation) -->
<!-- - Uni of Zürich : TA for Probability Theory I and Researcher for Center for Reproducible Science -->
<!-- -   graduated MSc Biostatistics  -->
<!-- -   started at RWD at Roche  -->
<!-- -   joined R&D at Roche in mid 2022  -->
<!--         - Project Lead Statistician in early Oncology Trials -->
<!--         - Study Statistician for phase 1-2, phase 3 trials -->
<!--         - Lead the development of R package "phase1b" -->

# My journey at Roche{.smaller}
::: columns
::: {.column width="50%"}       

-   first internal statistics presentation end 2022 on decision gating
    -   skills : R programming, writing functions, version control (GitLab, GitHub), presentation and communication
-   started `phase1b` in July 2023
-   `phase1b`'s first external tour at PSI and useR! in 2024
:::

::: {.column width="30%"}
```{r}
#| layout-ncol: 1
#| fig-width: 1
#| fig-height: 1
knitr::include_graphics("images/PSI_Stand.jpg", error = FALSE)

```
:::
:::

# Stats people in drug discovery understand :{.smaller}

...the combined Scientific and Business development of a therapy.

  - Roadblocks to end points e.g. recruitment rates and failures,
business assumptions and strategies
  - Drug pharmacokinetics and pharmacodynamics e.g. latent drug effect
  - Patient population e.g. rare diseases
  - Expectations from health authorities (regulators)
        

# Why Software Engineering ?{.smaller}

**Why find solutions when we can also build them ?**

-   Mathematics is Elegant

-   Building software can be inclusive and collaborative

-   I can create delightful experiences users and bring everyone along : *values of inclusion, building great products, having an impact*

## Use case: {.smaller}

```{r, warning = FALSE}
# | fig-alt: This table sets the scene of a problem a study statistician could have. At interim, there are 16/23 responders and they ask, what is the Posterior Probability, what is the Predictive Posterior Probability, is the decision to Go (continue drug development), Stop (terminate drug development) or in between called the "Grey Zone" where team may need additional supporting evidence to make a decision.
alpha = 
r_interim = 16
n_interim = 23
r_final = 23
n_final = 40
data.frame( Example = c("Responders", 
                      "n", 
                      "Response rate", 
                      "Posterior probability*", 
                      "Predictive posterior probability*",  
                      "Decision to develop molecule further :\n Go/Stop/Grey Zone"),
            Interim = c(r_interim, 
                        n_interim, 
                        paste(
                          round(
                            (r_interim/n_interim)*100, 
                            digits = 2), 
                          "%"), 
                        "ask phase1b", 
                        "ask phase1b", 
                        "ask phase1b"),
            Final = c(r_final, 
                      n_final, 
                      paste(
                        round(
                          (r_final/n_final)*100, 
                          digits = 2), 
                        "%"), 
                      "ask phase1b", 
                      "-", 
                      "ask phase1b") ) -> use_case

use_case %>% kbl(align = "c", caption = "A single arm novel therapeutic with an assumed control response rate is at most 60%") %>% kable_styling()
```




# Prior and Posterior of Beta Distribution for $\pi${.smaller}

::: {.columns}

::: {.column width="50%"}
-   Conjugate Prior \pi is $f(\pi)$, where $\pi \sim {Beta(\alpha, \beta)}$,
    same family of distribution of Posterior (see below)
-   We know the mean response rate (RR) is :
    $$\pi = \ \frac {\alpha}{\alpha + \beta}$$
-   Likelihood is $f(x|\pi)$, where $x \sim {Binomial(x, n)}$

:::

::: {.column width="50%"}
-   The updated Posterior $f( \pi | x )$ is again a $Beta$ distribution (same family as
    prior) : $$ \pi| \ x \sim Beta(\alpha + x, \ \beta + n - x)$$ where $x$ is
    the number of responders of current trial
- Posterior Probability :         
$P (\pi > 60 \% | \alpha + x, \beta + n - x )$
- Predictive Posterior Probability :        
$P (success \ or \  failure \ at \ final)$
:::

:::

# Posterior formulation :

$$  f(\pi | x)  \propto \  \pi^{x} (1-\pi)^{n-x} * \frac {1}{B(\alpha, \beta)} \pi^{\alpha-1}(1-\pi)^{\beta-1} 
$$

- (weighted sum version)

$$  f(\pi | x)  \propto \  \pi^{x} (1-\pi)^{n-x} * \sum_{j = 1}^{k} \ w_j \frac {1}{B(\alpha_j, \beta_j)} \pi^{\alpha_j-1}(1-\pi)^{\beta_j-1} 
$$

## Updating the Posterior
Using the formula for the mean and mode, where :

- $\alpha = 0.6, \beta = 0.4$ and 
- interim x = 16, interim n = 23 :
\
 $$ \pi = \ \frac {\alpha}{\alpha + \beta} = \ \frac {\alpha_{updated} }{\alpha_{updated} + \beta_{updated}} = \ \frac {16.6 }{16.6 + 7.4} ≈ 69.17 \% $$
 
  $$ mode (\pi) = \ \frac {\alpha_{updated} -1 }{\alpha_{updated} + \beta_{updated} - 2} = \ \frac {16.6 -1  }{16.6 + 7.4 - 2} ≈ 70.90 \% $$
    $$ median ( \pi) ≈ \ \frac {\alpha_{updated}}{ \alpha_{updated} + \beta_{updated} - \frac{2}{3} } ≈ 69.71 \% $$

## Graphical representation of the updated Posterior{.smaller}
- Prior parameters are $\alpha$ = 0.6, $\beta$ = 0.4
- Updated Posterior parameters are $\alpha$ = 16.6 and $\beta$ =  7.4
```{r , fig.align='center'}
# | fig-pos : "H"
# | out-width: "300%" 
# | out-height : "300%"
# | fig-alt: This plot shows how the prior can be updated from data and compares with the uniform beta prior. 
alpha = 0.6
beta = 0.4
interim_x = 16
interim_n = 23
alpha_updated = alpha + interim_x
beta_updated = beta + interim_n - interim_x
new_mean = alpha_updated / (alpha_updated + beta_updated )
new_mode = (alpha_updated - 1) / (alpha_updated + beta_updated - 2)
new_median = (alpha_updated - (1/3)) / (alpha_updated + beta_updated - (2/3))
xx <- seq(0, 1, .001)

uniform = dbeta(xx, 1, 1) #https://stackoverflow.com/questions/21991688/r-beta-function-relative-y-scale
prior_param = dbeta(xx, 0.6,0.4)
updated_param = dbeta(xx, 16.6, 7.4)

data = data.frame(rate = rep(xx, 3),
                  Density = c(uniform, prior_param, updated_param),
                  Category = c(rep("Uniform Prior a = b = 1", length(xx)), rep("Prior a = 0.4, b = 0.6", length(xx)), rep("Updated Posterior a = 16.6, b = 7.4", length(xx))))


ggplot(data) + geom_line(aes(x = rate, y = Density, colour = Category), size = 1.0) +
   ggtitle("Historical prior and Updated posterior distribution from 16 responders\n of 23 at interim analysis for a single arm oncology trial") + 
  scale_x_continuous(n.breaks = 10, labels = scales::percent_format()) +
  ylab("Density") +
  xlab("Response Rate") +
theme(plot.title = element_text(size=15, family = "Helvetica")) +
  scale_color_manual(values = c("#56B4E9", "#CC79A7", "#009E73")) +
  scale_y_continuous(limits = c(0, 7)) +
  geom_vline(xintercept = new_median, linetype = "dashed", size = 0.5, colour = "#009E73") +
geom_vline(xintercept = new_mean, linetype = "dashed", size = 0.5, colour = "#009")
```

# Effect on putting more weight on "more data"
```{r , fig.align='center'}
# | fig-pos : "H"
# | out-width: "300%" 
# | out-height : "300%"
# | fig-alt: This plot shows how the Mixture priors can be updated from data and compares with the uniform beta prior. 
a1 = 3
b1 = 12
weight1 = 0.6
weight2 = 0.4
alpha = a1
beta = b1
interim_x = 16
interim_n = 23
alpha_updated = alpha + interim_x
beta_updated = beta + interim_n - interim_x
new_mean = alpha_updated / (alpha_updated + beta_updated )
new_mode = (alpha_updated - 1) / (alpha_updated + beta_updated - 2)
xx <- seq(0, 1, .001)

dbetaMix1 = dbetaMix(x = xx, 
                     par = rbind(c(1, 1)), 
                     weights = 1)
dbetaMix2 = dbetaMix(x = xx, 
                     par = rbind(c(a1, b1)), 
                     weights = 1)
dbetaMix3 = dbetaMix(x = xx, 
                     par = rbind(c(1, 1), c(a1, b1)), 
                     weights = c(weight1, weight2))
dbetaMix4 = dbetaMix(x = xx, 
                     par = rbind(c(1, 1), c(a1, b1)), 
                     weights = c(weight2, weight1))
Mix1 = paste("Prior of a =", 1, ", b =", 1)
Mix2 = paste("Prior of a =", a1, "and b =", b1)
Mix3 = paste("Beta Mixture Prior:\n", weight1*100, "% weighting on uniform and\n", weight2*100, "% weighting on \nalpha =", a1, ", beta =", b1)
Mix4 = paste("Beta Mixture Prior:\n", weight2*100, "% weighting on uniform and\n", weight1*100, "% weighting on \nalpha =", a1, ", beta =", b1)
new_mean = a1/ sum(a1+ b1)

data = data.frame(rate = rep(xx, 4),
                  Density = c(dbetaMix1, dbetaMix2, dbetaMix3, dbetaMix4),
                  Category = c(rep(Mix1, length(xx)), 
                               rep(Mix2, length(xx)), 
                               rep(Mix3, length(xx)),
                               rep(Mix4, length(xx))))

ggplot(data) + geom_line(aes(x = rate, y = Density, colour = Category), size = 1.0) +
   ggtitle("Effect of diverse weighting contribution to Beta Mix Prior") + 
  scale_x_continuous(n.breaks = 10, labels = scales::percent_format()) +
  ylab("Density") +
  xlab("Response Rate") +
theme(plot.title = element_text(size=15, family = "Helvetica")) +
  scale_color_manual(values = c("#009E73", "#000", "#CC79A7", "#56B4E9")) +
  scale_y_continuous(limits = c(0, 5))
```

# Effect of Beta Mixture Prior contribution to Posterior 
```{r , fig.align='center', echo = FALSE, eval = TRUE}
# | fig-pos : "H"
# | out-width: "300%" 
# | out-height : "300%"
#| layout-ncol: 2 # make graph bigger
# | fig-alt: This plot shows how the Mixture priors can be updated from data and compares with the uniform beta prior. 
uniform_alpha = 1
uniform_beta = 1
alpha = 3 
beta = 12
interim_x = 16
interim_n = 23
final_n = 40
alpha_updated = alpha + interim_x
beta_updated = beta + interim_n - interim_x
uniform_mean = 0.5
uniform_mean_updated = (uniform_alpha + interim_x) / (uniform_alpha + interim_x + uniform_beta + interim_n - interim_x)
non_uniform_mean = alpha / sum(alpha, beta)
non_uniform_mean_updated = alpha_updated / (alpha_updated + beta_updated + interim_n)
non_uniform_mode_updated = (alpha_updated - 1) / (alpha_updated + beta_updated - 2)
beta_binomMix_mean = (0.2*(uniform_mean_updated) + 0.8*(non_uniform_mean_updated))*final_n
xx <- seq(0, 1, .001)
weight1 = 0.8
weight2 = 0.2

dbetaMix1 = dbetaMix(x = xx, par = rbind(c(uniform_alpha, uniform_beta)), weights = 1)
dbetaMix2 = dbetaMix(x = xx, par = rbind(c(alpha, beta)), weights = 1)
dbetabinomMix3 = dbetabinomMix(x = 0:40, 
                               m = 40, 
                               par = rbind(c(uniform_alpha + interim_x, 
                                             uniform_beta + interim_n - interim_x), 
                                           c(alpha + interim_x, 
                                             beta + interim_n - interim_x)), 
                               weights = c(0.8, 0.2))

dbetabinomMix3 = dbetabinomMix(x = 0:40, 
                               m = 40, 
                               par = rbind(c(1, 1), 
                                           c(3, 12)), 
                               weights = c(0.8, 0.2)) 


dbetabinomMix4 = dbetabinomMix(x = 0:40, 
                               m = 40, 
                               par = rbind(c(1, 1), 
                                           c(3, 12)), 
                               weights = c(0.2, 0.8)) 

data0 <-  data.frame(rate = rep(xx, 2),
                  Density = c(dbetaMix1, dbetaMix2),
                  Category = c(rep("Uniform Prior", length(xx)), 
                               rep(paste0("Beta(", alpha, ",", beta, ")"), length(xx))))

data1 <- data.frame(responders = rep(c(seq(0, 40, 1)), 2),
                    Density = c(dbetabinomMix3, dbetabinomMix4),
                    Category = c( rep("80% on Uniform Prior", 41), rep("20% on Uniform Prior", 41) ))

                    
p1 <- ggplot(data0) + geom_line(aes(x = rate, y = Density, colour = Category), size = 1.0) +
  ggtitle("Priors of Beta(1,1) and Beta(3, 12)") + 
  scale_x_continuous(n.breaks = 10, labels = scales::percent_format()) +
  ylab("Density") +
  theme(axis.text=element_text(size=15), legend.text = element_text(size = 15), plot.title = element_text(size = 15))
  # xlab("Response Rate") + theme(legend.position = "none") 
  # geom_vline(xintercept = non_uniform_mean, linetype = "dashed", size = 0.5, colour = "#009E73") 

p2 <- ggplot(data1) + geom_line(aes(x = responders, y = Density, colour = Category), size = 1.0) +
  ggtitle("Updated Beta Binomial Mixture Posterior") + 
  ylab("Density") +
  xlab("Number of Responders") +
  theme(axis.text=element_text(size=15), legend.text = element_text(size = 15), plot.title = element_text(size = 15))
  # geom_vline(xintercept = beta_binomMix_mean, linetype = "dashed", size = 0.5, colour = "#009E73")

# p3 <- ggplot(data2) + geom_line(aes(x = 0:final_n, y = Density), size = 1.0) +
#   ggtitle("Updated Beta Binomial Mixture\nPosterior (density) from weighted\nPriors 20% * Beta(1,1) and 80% * Beta(3,12)") + 
#   ylab("Density") +
#   xlab("Number of Responders") 
#   # geom_vline(xintercept = beta_binomMix_mean, linetype = "dashed", size = 0.5, colour = "#009E73")

# plot_grid(p1, p2, labels = c('A', 'B', 'C'), label_size = 12)
```

```{r}
#| layout-ncol: 2 # make graph bigger
#| column: page-right
#| fig-alt : "These two graphs side by side show that by increasing the threshold for an Efficacy or Go decision, the number of responders out of 40 is higher with the higher threshold, ie 35 patients instead of 32 patients of 40"

p1
p2
```




## A variety of Priors{.smaller}

- To illustrate how density of Prior changes with increased sample size even though mean is the same
```{r ,fig.align='center', eval = TRUE}
# | out-width: "70%" 
# | fig-alt: This plot shows how the priors of mean 50% can have improving precision with increased sample size. 

xx <- seq(0, 1, .001)

data = data.frame(
  rate = rep(xx, 4),
  Density = c(dbeta(xx, 10, 10), 
              dbeta(xx, 20, 20), 
              dbeta(xx, 30, 30), 
              dbeta(xx, 40, 40) ),
  Category = c(rep("alpha = beta = 10", length(xx)), 
               rep("alpha = beta = 20", length(xx)), 
               rep("alpha = beta = 30", length(xx)),
               rep("alpha = beta = 40", length(xx)) 
  )
)

ggplot(data) + geom_line(aes(x = rate, y = Density, colour = Category), size = 1.0) +
   ggtitle("Priors of mean 50% can have improving precision with increased sample size") + 
  scale_x_continuous(n.breaks = 10, labels = scales::percent_format()) +
  ylab("Density") +
  xlab("Response Rate") +
  geom_vline(xintercept = 0.5, linetype = "dotted", colour = "blue") +
theme(plot.title = element_text(size=15, family = "Helvetica")) +
  scale_color_manual(values = c("#56B4E9", "#CC79A7", "#009E73", "blue")) +
  scale_y_continuous(limits = c(0, 8)) 
```

## A variety of Posteriors{.smaller}

- To illustrate how density of Posterior changes with increased sample size even though mean is the same

```{r, fig.align='center'}
# | out-width: "70%" 
# | fig-alt: This plot shows how the priors of mean 50% can have improving precision with increased sample size. 
x = 16
n = 23
final_n = 40
length = length(0:final_n)

data11 = data.frame(
  rate = rep(0:final_n, 4),
  Density = c(dbetabinomMix(x = 0:final_n, 
                            m = final_n, 
                            par = rbind(c(10 + x, 10 + n - x)),
                            weights = 1), 
              dbetabinomMix(x = 0:final_n, 
                            m = final_n, 
                            par = rbind(c(20 + x, 20 + n - x)), 
                            weights = 1),
              dbetabinomMix(x = 0:final_n, 
                            m = final_n, 
                            par = rbind(c(30 + x, 30 + n - x)),
                            weights = 1), 
              dbetabinomMix(x = 0:final_n, 
                            m = final_n, 
                            par = rbind(c(40 + x, 40 + n -x)),
                            weights = 1)),
  Category = c(rep("alpha = beta = 10", length), 
               rep("alpha = beta = 20", length), 
               rep("alpha = beta = 30", length),
               rep("alpha = beta = 40", length) 
  )
)

ggplot(data11) + geom_line(aes(x = rate, y = Density, colour = Category), size = 1.0) +
   ggtitle("Updated Posteriors of Priors of mean 50% with increasing sample size and \ndata is 16 of 23 responders") + 
  ylab("Density") +
  xlab("Response Rate") +
  scale_x_continuous(breaks = seq(0, 40, by = 4)) +
  geom_vline(xintercept = 0.5*final_n, linetype = "dotted", colour = "blue") +
theme(plot.title = element_text(size=15, family = "Helvetica")) +
  scale_color_manual(values = c("#56B4E9", "#CC79A7", "#009E73", "blue")) 
```


# History and how to install : {.smaller}

-   2015 : Started as a need in Roche's early development group, package development led by Daniel
    Sabanés Bové in 2015.

-   2023 : Refactoring, Renaming, adding Unit and Integration tests as current State-of-Art Software Engineering practice.

-   100% written in R and Open Source.

-   website :
    [genentech.github.io/phase1b/](genentech.github.io/phase1b/)

```{r, eval = FALSE, echo = TRUE, warning = FALSE}
library(devtools)
devtools::install_github("https://github.com/Genentech/phase1b")
library(phase1b)
```


```{r}
# 2 mins
# The benefit of a Bayesian approach is the possibility to account for prior data (Thall &amp; Simon,
# 1994) in that a new drug may have shown some signals of efficacy owing to its proposed
# mode of action, or similar activity based on prior data.
# show graph of go, stop, eval zones 
## Terminology

# - A "look" is a stop
# - A stop is when a rule is applied
# - The rule is specified for Go, Stop or Evaluate (Grey zone)
# - If the rule is met, the result is Go, Stop or Evaluate (Grey zone)
# - Rules are applied at interim or final 
# - Go = Success = Efficacious
# - Stop = Failure = Futile
# - Rule = Criteria, e.g. Go rule is a Go Criteria

```



## `postprob()` example (Lee & Liu, 2008){.smaller}

```{r}
r_interim = 16
n_interim = 23
r_final = 23
n_final = 40
soc_rr = 0.60
soc_rr_percent = paste(soc_rr*100, "%")
data.frame( Example = c("Responders", 
                      "n", 
                      "Response rate", 
                      "Standard of Care Response rate",
                      "Posterior probability"), 
            Interim = c(r_interim, 
                        n_interim, 
                        paste(
                          round(
                            (r_interim/n_interim)*100, 
                            digits = 2), 
                          "%"), 
                        soc_rr_percent,
                        "postprob( ) call from phase1b" )) -> use_case

use_case %>% kbl(align = "c") %>% kable_styling(font_size = 25)
```

```{r, echo = TRUE, warning = FALSE}
postprob(x = 16, n = 23, p = 0.60, par = c(0.6, 0.4))
```


# Posterior Probability{.smaller}

- Interim trial is efficacious if posterior probability exceeds 70% or P( RR ≥ 60 % | data ) > 70\% 

```{r, fig.align='center'}
#| label: fig-post
#| layout-ncol: 1 # make graph bigger
#| column: page-right
#| fig-alt : "This graphs side by side show that by increasing number of responders out of 23 reaches our TPP threshold"
TPP = 0.6
n =23
plotthis = data.frame(x = c(0:n),
                      posterior = c(postprob(x = 0:n,  #P(RR ≥ TPP | x, a, b)
                                             n = n,
                                             p = TPP,
                                             par =
                                                 c(0.6, 0.4))))
plotthis$success = c(rep("FALSE", 15), rep("TRUE", 9)) #P(RR ≥ TPP | x, a, b) > 70%



ggplot(plotthis) +
  geom_point(aes(x = x,
                 y = posterior,
                 col = success)) +
  ggtitle(paste("Posterior probability that Response Rate ≥ 60% given number of responders with ", n, "patients.")) +
  ylab("Posterior Probability") +
  xlab("Number of responders") +
  scale_x_continuous(breaks = seq(0, n, by = 2)) +
  theme(text = element_text(size = 20)) +
  scale_color_manual(values = c("#D55E00", "#009E73")) + 
  theme_gray(base_size = 13)
```

## Beta prior mixture{.smaller}

<!-- {\displaystyle {\frac {\alpha -1}{\alpha +\beta -2}}\!}  -->

- `phase1b` facilitates the flexibility of using various priors and its respective weightings:

                 Prior is P_E ~ sum(weights * beta(parE[, 1], parE[, 2]))

```{r, echo = TRUE, results='hide'}
a = postprob(x = 16,
             n = 23,
             p = 0.60,
             parE = c(0.6, 0.4), weights = 1)

b = postprob(x = 16,
             n = 23,
             p = 0.60,
             parE = c(2, 4), weights = 1)

0.5*(a + b)

postprob(x = 16,
             n = 23,
             p = 0.60,
             parE = rbind(c(0.6, 0.4), c(2, 4)), weights = c(0.5, 0.5))
```


- Posterior formulation :

$$  f(\pi | x)  \propto \  \pi^{x} (1-\pi)^{n-x}\sum_{j = 1}^{k} \ w_j \frac {1}{B(\alpha_j, \beta_j)} \pi^{\alpha_j-1}(1-\pi)^{\beta_j-1} 
$$

## `predprob()` example (Lee & Liu, 2008){.smaller}
```{r}
r_interim = 16
n_interim = 23
r_final = 23
n_final = 40
soc_rr = 0.60
soc_rr_percent = paste(soc_rr*100, "%")
data.frame( Example = c("Responders", 
                      "n", 
                      "Response rate", 
                      "Standard of Care Response rate",
                      "Predictive Posterior probability"), 
            Interim = c(r_interim, 
                        n_interim, 
                        paste(
                          round(
                            (r_interim/n_interim)*100, 
                            digits = 2), 
                          "%"), 
                        soc_rr_percent,
                        "predprob( ) call from phase1b")) -> use_case
use_case %>% kbl(align = "c") %>% kable_styling(font_size = 20)
```


```{r, echo = TRUE, warning = FALSE}
control = 0.6
confidence_seventy = 0.7
result <- predprob(
  x = 16, n = 23, Nmax = 40, p = control, thetaT = confidence_seventy,
  parE = c(0.6, 0.4)
)
result$result
confidence_ninety = 0.9
result_high_thetaT <- predprob(
  x = 16, n = 23, Nmax = 40, p = control, thetaT = confidence_ninety,
  parE = c(0.6, 0.4)
)
result_high_thetaT$result
```

## Predictive Posterior Probability 

\n

```{r}
#| label: fig-histogram
#| fig-cap: "Predictive Posterior CDF for different Efficacy Rules"
#| fig-subcap:
#|   - $P (\pi > 0.6 | \ data )$ > 70% #"Efficacious if Pred. Posterior Prob > 60 %" 
#|   - $P (\pi > 0.6 | \ data )$ > 90% #"Efficacious if Pred. Posterior Prob > 90 %" 
#| layout-ncol: 2 # make graph bigger
#| column: page-right
#| fig-alt : "These two graphs side by side show that by increasing the threshold for an Efficacy or Go decision, the number of responders out of 40 is higher with the higher threshold, ie 35 patients instead of 32 patients of 40"

ggplot(df_thetaTlow) +
  geom_point(aes(x = counts, y = posterior, colour = success)) +
  scale_x_discrete(limits = c(seq(0, 33, by = 1))) +
  xlab("\nFuture successful reponders") +
  ylab("Probability\n") +
  ggtitle("With lower threshold : \n25 of 40 responders needed to achieve a Go decision")  +
  theme(text = element_text(size = 20)) +
  scale_color_manual(values = c("#D55E00", "#009E73"))

ggplot(df_thetaThigh) +
  geom_point(aes(x = counts, y = posterior, colour = success)) +
   scale_x_discrete(limits = c(seq(0, 33, by = 1))) +
    xlab("\nFuture successful reponders") +
  ylab("Probability\n") +
  ggtitle("With higher threshold : \n28 of 40 responders needed to achieve a Go decision") +
  theme(text = element_text(size = 20)) +
  scale_color_manual(values = c("#D55E00", "#009E73")) 
```
# Operating Characteristics

## Operating Characteristics : threshold for Success (and failure):

- Efficacy criteria, e.g. we would stop for Efficacy if :

`Pr( RR > p1) > tU`

- Futility criteria, eg. we would stop for Futility if :

`Pr( RR < p0) > tL`

## Rules and Operating characteristics. A use case for `ocPostprob()`: {.smaller}
-   Look for Efficacy: Go if $P( \pi > 60\% | \ data ) > 90 \%$
-   Look for Futility: Stop if $P( \pi < 60\% | \ data ) > 70 \%$
-   Prior of treatment arm $Beta(0.6, 0.4)$.

```{r, echo = TRUE, warning = FALSE}
set.seed(2025)
res <- ocPostprob(
  nnE = c(23, 40), truep = 0.60, p0 = 0.60, p1 = 0.69, tL = 0.70, tU = 0.90, parE = c(0.6, 0.4),
  sim = 500, wiggle = TRUE, nnF = c(23, 40)
)
res$oc
```

## State-of-Art R software/packages are currently valuable because it makes robust analysis, faster. One example is the `phase1b` {.smaller}

In a nutshell : 
\
A robust, reliable and reproducible tool that calculates the Bayesian posterior probability             and predictive posterior probability.

What is a state-of-art tool ? Check out a past workshop [here](https://openpharma.github.io/workshop-r-swe-sf/listing.html)

- Integrative and Unit testing
- Example and good documentation
- Assertions on input arguments and internal results that get passed on
- Check expected and actual results

## Sharing the Success story: Touring `phase1b`

::: columns
::: {.column width="50%"}
-   [PSI](https://www.psiweb.org/conferences/about-the-conference) June 2024 conference in Netherlands
\
-   [useR!2024](https://events.linuxfoundation.org/user/) Salzburg
\
- Various Pharma (UCB, Bristol Myer Squibb)
\
-   [PHUSE](https://www.phuse-events.org/attend/frontend/reg/thome.csp?pageID=40702&eventID=64&traceRedir=2) September 2024 in Basel
\
-   [University of Basel](https://accio.github.io/AMIDD/) December 2024
:::

::: {.column width="50%"}
```{r}
knitr::include_graphics("images/hex3.png", error = FALSE)

```
:::
:::


## Expanded features {.smaller}
.... and wiggle room!

```{r}
# | fig-alt: "This table has on the first column other phase1b call functions and on the next columns, have check boxes that show Features like SOC uncertainty, single-arm, two-arm ,simulation , plotting and boundaries" 
Features <- read.csv(file = "phase1b_FeatureTable - Sheet1.csv", header = TRUE, sep  = ",")
names(Features) <- c(" ", "SOC uncertainty", "single-arm", "two-arm", "simulation", "plotting", "boundaries")
Features[is.na(Features)] <- ""
Features[Features == 1] <- "✔️"
# what are these features, diff between two arm and randomisation say what kind of trials this can support
Features %>% kbl(align = "c") %>% kable_styling(position = "center", font_size = 18) %>% kable_classic(lightable_options = "hover", html_font = "\"Source Sans Pro\", helvetica, sans-serif") 
```

# Concluding remarks{.smaller}
```{r}
# | fig-alt : "This hexagon is the R sticker for phase1b R package. It has a bright purple background, light orange border and the title is in fuschia. The graph in the middle is a CDF distribution in dots that changes from red dots to green dots to indicate a stop to go decision"
```
-  So far, any knowledge, has not been beyond me.

-  Whenever I learn at my own pace, I tend to learn. Tests and deadlines are very helpful.

- I have seen that going slower can have efficiency gains (software development).

- When I respect that Statistics, etc is a discipline, with its on set of tools, I can be "better" at it.

- I can change careers again if my interests change by following the above.

# Questions and collaboration

- I look forward to seeing the great work that you do

- Maybe we will collaborate one day, or you will be part of open software development

- If you have feedback, questions, feel free to contact [me](audreytyeo@gmail.com) 

-   Next `phase1b` talk at the [Deutsche Arbeitsgemeinschaft Statistik 2025](https://dagstat2025.de/#) : Practical Bayesian Statistics : A gentle refresher on probability theory, Bayesian Framework and Intuition for effective application in Biostatistics

#
         Autumn Glow [excerpt] 2021
         
            - Audrey Yeo -
         
         I am unsure of the darkened stains of rain
         But I captured the brazen autumn glow
         Before it went away
         Kept all of my notes like I were to read them out one day
         Held on to my words so my hunches don’t fray
         
     


# Some references

-   Thall P F, Simon R (1994), Practical Guidelines for Phase IIB
    Clinical Trials, Biometrics, 50, 337-349

-   Lee J J, Liu D D (2008), A Predictive probability design for phase
    II cancer clinical trials, 5(2), 93-106, Clinical Trials

-   Yeo, A T, Sabanés Bové D, Elze M, Pourmohamad T, Zhu J, Lymp J,
    Teterina A (2024). Phase1b : Calculations for decisions on Phase 1b
    clinical trials. R package version 1.0.0,
    <https://genentech.github.io/phase1b>
    
-   Inclusive Speaker Orientation [Linux Foundation](https://training.linuxfoundation.org/training/inclusive-speaker-orientation/)

# Some more references 

-   Zeileis, Fisher, Hornik, Ihaka, McWhite, Murrell, Stauffer, Wilke (2020). 
colorspace: A Toolbox for Manipulating and Assessing Colors and Palettes. Journal of Statistical Software.

-   [Code for this presentation](www.audreyyeCH.github.io/About)

    
      


# 

         “Sometimes taking time is actually a shortcut.”
         
         
                        What I talk about when I talk about running.
                        
                        
                  - Haruki Murakami - 

