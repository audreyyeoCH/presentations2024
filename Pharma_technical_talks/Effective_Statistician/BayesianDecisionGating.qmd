---
# title: "A Bayesian approach to decision making in early development clinical trials: An R solution"
# subtitle: "An open source R package"
# author: "Audrey Yeo"
# institute: ""
format: 
 revealjs:
    code-fold: false
    width: 1280
    height: 720
    chalkboard: true
preload-iframes: true
editor: 
  markdown: 
    wrap: 72
csl: apa-single-spaced.csl
footer: "Audrey Yeo"
---

```{r, echo = FALSE, warning = FALSE}
# Load relevant packages
library(testthat)
library(tidyverse)
library(flextable)
library(ggplot2)
library(float)
library(utils)
library(kableExtra)
library(formattable)
library(ggfun)
library(hexSticker)
library(lattice)
library(devtools)
devtools::install_github("https://github.com/Genentech/phase1b", force = TRUE)
library(phase1b)
library(cowplot)
```

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.pos = 'H')
```

```{r}
# Mode
Mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}
```


```{r}
# | fig-alt : "This hexagon is the R sticker for phase1b R package. It has a bright purple background, light orange border and the title is in fuschia. The graph in the middle is a CDF distribution in dots that changes from red dots to green dots to indicate a stop to go decision"
control = 0.6
thetaT_low = 0.6
result <- predprob(
  x = 16, n = 23, Nmax = 40, p = control, thetaT = thetaT_low,
  parE = c(0.6, 0.4)
)

thetaT_high = 0.9
result_high_thetaT <- predprob(
  x = 16, n = 23, Nmax = 40, p = control, thetaT = thetaT_high,
  parE = c(0.6, 0.4)
)
data = rbind(result$table, result_high_thetaT$table)

data$thetaT = c(rep("60%", 18), rep("90%", 18))
df_thetaTlow <- data %>% filter(thetaT == "60%") 
df_thetaTlow$cumul_x <- df_thetaTlow$counts + 16

df_thetaThigh <- data %>% filter(thetaT == "90%") 
df_thetaThigh$cumul_x <- df_thetaThigh$counts + 16
```


# A Bayesian approach to  decision making in early development clinical trials: An R solution {background-iframe="lego-loader/dist/index.html"} 
\
**Audrey Yeo**
Bristol Myers Squibb - CH, IN 2024
\
***This presentation has ALT text and as much as possible, uses colour-blind friendly palettes***

# Early oncology trials and why `phase1b`?{.smaller}

```{r}
# | fig-alt : "This hexagon is the R sticker for phase1b R package. It has a bright purple background, light orange border and the title is in fuschia. The graph in the middle is a CDF distribution in dots that changes from red dots to green dots to indicate a stop to go decision"
```

::: {#layout-nrow=6}
![](images/hex3.png){width=15%}  ![](images/hex6.png){width=15%}  ![](images/hex9.png){width=15%}  ![](images/hex5.png){width=15%} ![](images/hex1.png){width=15%} 
:::


# Prior and Posterior of Beta Distribution for response rate {.smaller}
    
-   Conjugate Prior \pi is $f(\pi)$, where $\pi \sim {Beta(\alpha, \beta)}$,
    same family of distribution of Posterior (see below)
-   We know the mean response rate (RR) is :
    $$\pi = \ \frac {\alpha}{\alpha + \beta}$$
-   Likelihood is $f(x|\pi)$, where $x \sim {Binomial(x, n)}$
-   The updated Posterior $f( \pi | x )$ is again a $Beta$ distribution (same family as
    prior) : $$ \pi| \ x \sim Beta(\alpha + x, \ \beta + n - x)$$ where $x$ is
    the number of responders of current trial

```{r}
# 2 mins
# The benefit of a Bayesian approach is the possibility to account for prior data (Thall &amp; Simon,
# 1994) in that a new drug may have shown some signals of efficacy owing to its proposed
# mode of action, or similar activity based on prior data.
# show graph of go, stop, eval zones 
```

# History and how to install : {.smaller}

-   2015 : Started as a need in Roche's early development group, package development led by Daniel
    Sabanés Bové in 2015.

-   2023 : Refactoring, Renaming, adding Unit and Integration tests as current State-of-Art Software Engineering practice.

-   100% written in R and Open Source.

-   website :
    [genentech.github.io/phase1b/](genentech.github.io/phase1b/)

```{r, eval = FALSE, echo = TRUE, warning = FALSE}
library(devtools)
devtools::install_github("https://github.com/Genentech/phase1b")
library(phase1b)
```


## Use case: {.smaller}

```{r, warning = FALSE}
# | fig-alt: This table sets the scene of a problem a study statistician could have. At interim, there are 16/23 responders and they ask, what is the Posterior Probability, what is the Predictive Posterior Probability, is the decision to Go (continue drug development), Stop (terminate drug development) or in between called the "Grey Zone" where team may need additional supporting evidence to make a decision.
alpha = 
r_interim = 16
n_interim = 23
r_final = 23
n_final = 40
data.frame( Example = c("Responders", 
                      "n", 
                      "Response rate", 
                      "Posterior probability*", 
                      "Predictive posterior probability*",  
                      "Decision to develop molecule further :\n Go/Stop/Grey Zone"),
            Interim = c(r_interim, 
                        n_interim, 
                        paste(
                          round(
                            (r_interim/n_interim)*100, 
                            digits = 2), 
                          "%"), 
                        "ask phase1b", 
                        "ask phase1b", 
                        "ask phase1b"),
            Final = c(r_final, 
                      n_final, 
                      paste(
                        round(
                          (r_final/n_final)*100, 
                          digits = 2), 
                        "%"), 
                      "ask phase1b", 
                      "-", 
                      "ask phase1b") ) -> use_case

use_case %>% kbl(align = "c", caption = "A single arm novel therapeutic with an assumed control response rate is at most 60%") %>% kable_styling()
```
\
\
* Posterior Probability : $P (\pi > 60 \% | \alpha + x, \beta + n - x )$
\
* Predictive Posterior Probability : $P (success \ or \  failure \ at \ final)$


## Updating the Posterior
<!-- - The updated Posterior will have the parameters $\alpha + x$ and -->
<!-- $\beta + n - x$.   -->
<!-- - With the prior of $Beta(0.6, 0.4)$ and the result of our interim results our Posterior has these parameters:  \ $Beta(16.6, 7.4)$.  -->
Using the formula for the mean and mode, where :

- $\alpha = 0.6, \beta = 0.4$ and 
- interim x = 16, interim n = 23 :
\
 $$ \pi = \ \frac {\alpha}{\alpha + \beta} = \ \frac {\alpha_{updated} }{\alpha_{updated} + \beta_{updated}} = \ \frac {16.6 }{16.6 + 7.4} ≈ 69.17 \% $$
 
  $$ mode (\pi) = \ \frac {\alpha_{updated} -1 }{\alpha_{updated} + \beta_{updated} - 2} = \ \frac {16.6 -1  }{16.6 + 7.4 - 2} ≈ 70.90 \% $$
    $$ median ( \pi) ≈ \ \frac {\alpha_{updated}}{ \alpha_{updated} + \beta_{updated} - \frac{2}{3} } ≈ 69.71 \% $$
  


## Graphical representation of the updated Posterior{.smaller}
- Prior parameters are $\alpha$ = 0.6, $\beta$ = 0.4
- Updated Posterior parameters are $\alpha$ = 16.6 and $\beta$ =  7.4
```{r , fig.align='center'}
# | fig-pos : "H"
# | out-width: "300%" 
# | out-height : "300%"
# | fig-alt: This plot shows how the prior can be updated from data and compares with the uniform beta prior. 
alpha = 0.6
beta = 0.4
interim_x = 16
interim_n = 23
alpha_updated = alpha + interim_x
beta_updated = beta + interim_n - interim_x
new_mean = alpha_updated / (alpha_updated + beta_updated )
new_mode = (alpha_updated - 1) / (alpha_updated + beta_updated - 2)
new_median = (alpha_updated - (1/3)) / (alpha_updated + beta_updated - (2/3))
xx <- seq(0, 1, .001)

data = data.frame(rate = rep(xx, 3),
                  Density = c(dbeta(xx, 1, 1), dbeta(xx, 0.6,0.4), dbeta(xx, 16.6, 7.4)),
                  Category = c(rep("Uniform Prior a = b = 1", length(xx)), rep("Prior a = 0.4, b = 0.6", length(xx)), rep("Updated Posterior a = 16.6, b = 7.4", length(xx))))


ggplot(data) + geom_line(aes(x = rate, y = Density, colour = Category), size = 1.0) +
   ggtitle("Historical prior and Updated posterior distribution from 16 responders\n of 23 at interim analysis for a single arm oncology trial") + 
  scale_x_continuous(n.breaks = 10, labels = scales::percent_format()) +
  ylab("Density") +
  xlab("Response Rate") +
theme(plot.title = element_text(size=15, family = "Helvetica")) +
  scale_color_manual(values = c("#56B4E9", "#CC79A7", "#009E73")) +
  scale_y_continuous(limits = c(0, 7)) +
  geom_vline(xintercept = new_median, linetype = "dashed", size = 0.5, colour = "#009E73") +
geom_vline(xintercept = new_mean, linetype = "dashed", size = 0.5, colour = "#009")
```
# Effect on putting more weight on "more data"
```{r , fig.align='center'}
# | fig-pos : "H"
# | out-width: "300%" 
# | out-height : "300%"
# | fig-alt: This plot shows how the Mixture priors can be updated from data and compares with the uniform beta prior. 
a1 = 3
b1 = 12
weight1 = 0.6
weight2 = 0.4
alpha = a1
beta = b1
interim_x = 16
interim_n = 23
alpha_updated = alpha + interim_x
beta_updated = beta + interim_n - interim_x
new_mean = alpha_updated / (alpha_updated + beta_updated )
new_mode = (alpha_updated - 1) / (alpha_updated + beta_updated - 2)
xx <- seq(0, 1, .001)

dbetaMix1 = dbetaMix(x = xx, 
                     par = rbind(c(1, 1)), 
                     weights = 1)
dbetaMix2 = dbetaMix(x = xx, 
                     par = rbind(c(a1, b1)), 
                     weights = 1)
dbetaMix3 = dbetaMix(x = xx, 
                     par = rbind(c(1, 1), c(a1, b1)), 
                     weights = c(weight1, weight2))
dbetaMix4 = dbetaMix(x = xx, 
                     par = rbind(c(1, 1), c(a1, b1)), 
                     weights = c(weight2, weight1))
Mix1 = paste("Prior of a =", 1, ", b =", 1)
Mix2 = paste("Prior of a =", a1, "and b =", b1)
Mix3 = paste("Beta Mixture Prior:\n", weight1*100, "% weighting on uniform and\n", weight2*100, "% weighting on \nalpha =", a1, ", beta =", b1)
Mix4 = paste("Beta Mixture Prior:\n", weight2*100, "% weighting on uniform and\n", weight1*100, "% weighting on \nalpha =", a1, ", beta =", b1)
new_mean = a1/ sum(a1+ b1)

data = data.frame(rate = rep(xx, 4),
                  Density = c(dbetaMix1, dbetaMix2, dbetaMix3, dbetaMix4),
                  Category = c(rep(Mix1, length(xx)), 
                               rep(Mix2, length(xx)), 
                               rep(Mix3, length(xx)),
                               rep(Mix4, length(xx))))

ggplot(data) + geom_line(aes(x = rate, y = Density, colour = Category), size = 1.0) +
   ggtitle("Effect of diverse weighting contribution to Beta Mix Prior") + 
  scale_x_continuous(n.breaks = 10, labels = scales::percent_format()) +
  ylab("Density") +
  xlab("Response Rate") +
theme(plot.title = element_text(size=15, family = "Helvetica")) +
  scale_color_manual(values = c("#009E73", "#000", "#CC79A7", "#56B4E9")) +
  scale_y_continuous(limits = c(0, 7))
```
# Effect of Beta Mixture Prior contribution to Posterior 
```{r , fig.align='center', echo = FALSE, eval = TRUE}
# | fig-pos : "H"
# | out-width: "300%" 
# | out-height : "300%"
# | fig-alt: This plot shows how the Mixture priors can be updated from data and compares with the uniform beta prior. 
uniform_alpha = 1
uniform_beta = 1
alpha = 3 
beta = 12
interim_x = 16
interim_n = 23
final_n = 40
alpha_updated = alpha + interim_x
beta_updated = beta + interim_n - interim_x
uniform_mean = 0.5
uniform_mean_updated = (uniform_alpha + interim_x) / (uniform_alpha + interim_x + uniform_beta + interim_n - interim_x)
non_uniform_mean = alpha / sum(alpha, beta)
non_uniform_mean_updated = alpha_updated / (alpha_updated + beta_updated + interim_n)
non_uniform_mode_updated = (alpha_updated - 1) / (alpha_updated + beta_updated - 2)
beta_binomMix_mean = (0.2*(uniform_mean_updated) + 0.8*(non_uniform_mean_updated))*final_n
xx <- seq(0, 1, .001)
weight1 = 0.8
weight2 = 0.2

dbetaMix1 = dbetaMix(x = xx, par = rbind(c(uniform_alpha, uniform_beta)), weights = 1)
dbetaMix2 = dbetaMix(x = xx, par = rbind(c(alpha, beta)), weights = 1)
dbetabinomMix3 = dbetabinomMix(x = 0:40, 
                               m = 40, 
                               par = rbind(c(uniform_alpha + interim_x, 
                                             uniform_beta + interim_n - interim_x), 
                                           c(alpha + interim_x, 
                                             beta + interim_n - interim_x)), 
                               weights = c(0.2, 0.8))

dbetabinomMix3 = dbetabinomMix(x = 0:40, 
                               m = 40, 
                               par = rbind(c(1, 1), 
                                           c(3, 12)), 
                               weights = c(0.2, 0.8)) 

data0 <-  data.frame(rate = rep(xx, 2),
                  Density = c(dbetaMix1, dbetaMix2),
                  Category = c(rep("Uniform Prior", length(xx)), 
                               rep(paste0("Beta(", alpha, ",", beta, ")"), length(xx))))

data1 <- data.frame(responders = c(seq(0, 40, 1)),
                    Density = c(dbetabinomMix3))
                    
p1 <- ggplot(data0) + geom_line(aes(x = rate, y = Density, colour = Category), size = 1.0) +
  ggtitle("Two Priors of Beta(1,1) and Beta(3, 12)") + 
  scale_x_continuous(n.breaks = 10, labels = scales::percent_format()) +
  ylab("Density") +
  xlab("Response Rate") + theme(legend.position = "none") 
  # geom_vline(xintercept = non_uniform_mean, linetype = "dashed", size = 0.5, colour = "#009E73") 

p2 <- ggplot(data1) + geom_line(aes(x = 0:final_n, y = Density), size = 1.0) +
  ggtitle("Updated Beta Binomial Mixture\nPosterior (density) from weighted\nPriors 80% * Beta(1,1) and 20% * Beta(3,12)") + 
  ylab("Density") +
  xlab("Number of Responders") 
  # geom_vline(xintercept = beta_binomMix_mean, linetype = "dashed", size = 0.5, colour = "#009E73")

plot_grid(p1, p2, labels = c('A', 'B'), label_size = 12)
```

## A variety of Priors{.smaller}

- To illustrate how density of Prior changes with increased sample size even though mean is the same
```{r ,fig.align='center', eval = TRUE}
# | out-width: "70%" 
# | fig-alt: This plot shows how the priors of mean 50% can have improving precision with increased sample size. 
xx <- seq(0, 1, .001)

data = data.frame(
  rate = rep(xx, 4),
  Density = c(dbeta(xx, 10, 10), 
              dbeta(xx, 20, 20), 
              dbeta(xx, 30, 30), 
              dbeta(xx, 40, 40) ),
  Category = c(rep("alpha = beta = 10", length(xx)), 
               rep("alpha = beta = 20", length(xx)), 
               rep("alpha = beta = 30", length(xx)),
               rep("alpha = beta = 40", length(xx)) 
  )
)

ggplot(data) + geom_line(aes(x = rate, y = Density, colour = Category), size = 1.0) +
   ggtitle("Priors of mean 50% can have improving precision with increased sample size") + 
  scale_x_continuous(n.breaks = 10, labels = scales::percent_format()) +
  ylab("Density") +
  xlab("Response Rate") +
  geom_vline(xintercept = 0.5, linetype = "dotted", colour = "blue") +
theme(plot.title = element_text(size=15, family = "Helvetica")) +
  scale_color_manual(values = c("#56B4E9", "#CC79A7", "#009E73", "blue")) +
  scale_y_continuous(limits = c(0, 8)) 
```

## A variety of Posteriors{.smaller}

- To illustrate how density of Posterior changes with increased sample size even though mean is the same

```{r, fig.align='center'}
# | out-width: "70%" 
# | fig-alt: This plot shows how the priors of mean 50% can have improving precision with increased sample size. 
x = 16
n = 23
final_n = 40
length = length(0:final_n)

data11 = data.frame(
  rate = rep(0:final_n, 4),
  Density = c(dbetabinomMix(x = 0:final_n, 
                            m = final_n, 
                            par = rbind(c(10 + x, 10 + n - x)),
                            weights = 1), 
              dbetabinomMix(x = 0:final_n, 
                            m = final_n, 
                            par = rbind(c(20 + x, 20 + n - x)), 
                            weights = 1),
              dbetabinomMix(x = 0:final_n, 
                            m = final_n, 
                            par = rbind(c(30 + x, 30 + n - x)),
                            weights = 1), 
              dbetabinomMix(x = 0:final_n, 
                            m = final_n, 
                            par = rbind(c(40 + x, 40 + n -x)),
                            weights = 1)),
  Category = c(rep("alpha = beta = 10", length), 
               rep("alpha = beta = 20", length), 
               rep("alpha = beta = 30", length),
               rep("alpha = beta = 40", length) 
  )
)

ggplot(data11) + geom_line(aes(x = rate, y = Density, colour = Category), size = 1.0) +
   ggtitle("Updated Posteriors of Priors of mean 50% with increasing sample size and \ndata is 16 of 23 responders") + 
  ylab("Density") +
  xlab("Response Rate") +
  scale_x_continuous(breaks = seq(0, 40, by = 4)) +
  geom_vline(xintercept = 0.5*final_n, linetype = "dotted", colour = "blue") +
theme(plot.title = element_text(size=15, family = "Helvetica")) +
  scale_color_manual(values = c("#56B4E9", "#CC79A7", "#009E73", "blue")) 
```

## Terminology

- A "look" is a stop
- A stop is when a rule is applied
- The rule is specified for Go, Stop or Evaluate (Grey zone)
- If the rule is met, the result is Go, Stop or Evaluate (Grey zone)
- Rules are applied at interim or final 
- Go = Success = Efficacious
- Stop = Failure = Futile
- Rule = Criteria, e.g. Go rule is a Go Criteria


## `postprob()` example (Lee & Liu, 2008){.smaller}

```{r}
r_interim = 16
n_interim = 23
r_final = 23
n_final = 40
soc_rr = 0.60
soc_rr_percent = paste(soc_rr*100, "%")
data.frame( Example = c("Responders", 
                      "n", 
                      "Response rate", 
                      "Standard of Care Response rate",
                      "Posterior probability"), 
            Interim = c(r_interim, 
                        n_interim, 
                        paste(
                          round(
                            (r_interim/n_interim)*100, 
                            digits = 2), 
                          "%"), 
                        soc_rr_percent,
                        "postprob( ) call from phase1b" )) -> use_case

use_case %>% kbl(align = "c") %>% kable_styling(font_size = 25)
```

```{r, echo = TRUE, warning = FALSE}
postprob(x = 16, n = 23, p = 0.60, par = c(0.6, 0.4))
```


# Posterior Probability{.smaller}

- Interim trial is efficacious if posterior probability exceeds 70% or P( RR ≥ 60 % | data ) > 70\% 

```{r, fig.align='center'}
#| label: fig-post
#| layout-ncol: 1 # make graph bigger
#| column: page-right
#| fig-alt : "This graphs side by side show that by increasing number of responders out of 23 reaches our TPP threshold"
TPP = 0.6
n =23
plotthis = data.frame(x = c(0:n),
                      posterior = c(postprob(x = 0:n,  #P(RR ≥ TPP | x, a, b)
                                             n = n,
                                             p = TPP,
                                             par =
                                                 c(0.6, 0.4))))
plotthis$success = c(rep("FALSE", 15), rep("TRUE", 9)) #P(RR ≥ TPP | x, a, b) > 70%



ggplot(plotthis) +
  geom_point(aes(x = x,
                 y = posterior,
                 col = success)) +
  ggtitle(paste("Posterior probability that Response Rate ≥ 60% given number of responders with ", n, "patients.")) +
  ylab("Posterior Probability") +
  xlab("Number of responders") +
  scale_x_continuous(breaks = seq(0, n, by = 2)) +
  theme(text = element_text(size = 20)) +
  scale_color_manual(values = c("#D55E00", "#009E73")) + 
  theme_gray(base_size = 13)
```

## Beta prior mixture{.smaller}

<!-- {\displaystyle {\frac {\alpha -1}{\alpha +\beta -2}}\!}  -->

- `phase1b` facilitates the flexibility of using various priors and its respective weightings:

                 Prior is P_E ~ sum(weights * beta(parE[, 1], parE[, 2]))

```{r, echo = TRUE, results='hide'}
a = postprob(x = 16,
             n = 23,
             p = 0.60,
             parE = c(0.6, 0.4), weights = 1)

b = postprob(x = 16,
             n = 23,
             p = 0.60,
             parE = c(2, 4), weights = 1)

0.5*(a + b)

postprob(x = 16,
             n = 23,
             p = 0.60,
             parE = rbind(c(0.6, 0.4), c(2, 4)), weights = c(0.5, 0.5))
```


- Posterior formulation :

$$  f(\pi | x)  \propto \  \pi^{x} (1-\pi)^{n-x}\sum_{j = 1}^{k} \ w_j \frac {1}{B(\alpha_j, \beta_j)} \pi^{\alpha_j-1}(1-\pi)^{\beta_j-1} 
$$

## `predprob()` example (Lee & Liu, 2008){.smaller}
```{r}
r_interim = 16
n_interim = 23
r_final = 23
n_final = 40
soc_rr = 0.60
soc_rr_percent = paste(soc_rr*100, "%")
data.frame( Example = c("Responders", 
                      "n", 
                      "Response rate", 
                      "Standard of Care Response rate",
                      "Predictive Posterior probability"), 
            Interim = c(r_interim, 
                        n_interim, 
                        paste(
                          round(
                            (r_interim/n_interim)*100, 
                            digits = 2), 
                          "%"), 
                        soc_rr_percent,
                        "predprob( ) call from phase1b")) -> use_case
use_case %>% kbl(align = "c") %>% kable_styling(font_size = 20)
```


```{r, echo = TRUE, warning = FALSE}
control = 0.6
confidence_seventy = 0.7
result <- predprob(
  x = 16, n = 23, Nmax = 40, p = control, thetaT = confidence_seventy,
  parE = c(0.6, 0.4)
)
result$result
confidence_ninety = 0.9
result_high_thetaT <- predprob(
  x = 16, n = 23, Nmax = 40, p = control, thetaT = confidence_ninety,
  parE = c(0.6, 0.4)
)
result_high_thetaT$result
```

## Predictive Posterior Probability 

\n

```{r}
#| label: fig-histogram
#| fig-cap: "Predictive Posterior CDF for different Efficacy Rules"
#| fig-subcap:
#|   - $P (\pi > 0.6 | \ data )$ > 70% #"Efficacious if Pred. Posterior Prob > 60 %" 
#|   - $P (\pi > 0.6 | \ data )$ > 90% #"Efficacious if Pred. Posterior Prob > 90 %" 
#| layout-ncol: 2 # make graph bigger
#| column: page-right
#| fig-alt : "These two graphs side by side show that by increasing the threshold for an Efficacy or Go decision, the number of responders out of 40 is higher with the higher threshold, ie 35 patients instead of 32 patients of 40"

ggplot(df_thetaTlow) +
  geom_point(aes(x = counts, y = posterior, colour = success)) +
  scale_x_discrete(limits = c(seq(0, 33, by = 1))) +
  xlab("\nFuture successful reponders") +
  ylab("Probability\n") +
  ggtitle("With lower threshold : \n25 of 40 responders needed to achieve a Go decision")  +
  theme(text = element_text(size = 20)) +
  scale_color_manual(values = c("#D55E00", "#009E73"))

ggplot(df_thetaThigh) +
  geom_point(aes(x = counts, y = posterior, colour = success)) +
   scale_x_discrete(limits = c(seq(0, 33, by = 1))) +
    xlab("\nFuture successful reponders") +
  ylab("Probability\n") +
  ggtitle("With higher threshold : \n27 of 40 responders needed to achieve a Go decision") +
  theme(text = element_text(size = 20)) +
  scale_color_manual(values = c("#D55E00", "#009E73")) 
```
# Operating Characteristics

## Operating Characteristics : threshold for Success (and failure):

- Efficacy criteria, e.g. we would stop for Efficacy if :

`Pr( RR > p1) > tU`

- Futility criteria, eg. we would stop for Futility if :

`Pr( RR < p0) > tL`

## Rules and Operating characteristics. A use case for `ocPostprob()`: {.smaller}
-   Look for Efficacy: Go if $P( \pi > 60\% | \ data ) > 90 \%$
-   Look for Futility: Stop if $P( \pi < 60\% | \ data ) > 70 \%$
-   Prior of treatment arm $Beta(0.6, 0.4)$.

```{r, echo = TRUE, warning = FALSE}
set.seed(2025)
res <- ocPostprob(
  nnE = c(23, 40), truep = 0.60, p0 = 0.60, p1 = 0.69, tL = 0.70, tU = 0.90, parE = c(0.6, 0.4),
  sim = 500, wiggle = TRUE, nnF = c(23, 40)
)
res$oc
```

## Expanded features {.smaller}
.... and wiggle room!

```{r}
# | fig-alt: "This table has on the first column other phase1b call functions and on the next columns, have check boxes that show Features like SOC uncertainty, single-arm, two-arm ,simulation , plotting and boundaries" 
Features <- read.csv(file = "phase1b_FeatureTable_feature - Sheet1.csv", header = TRUE, sep  = ",")
names(Features) <- c(" ", "SOC uncertainty", "single-arm", "two-arm", "simulation", "plotting", "boundaries")
Features[is.na(Features)] <- ""
Features[Features == 1] <- "✔️"
# what are these features, diff between two arm and randomisation say what kind of trials this can support
Features %>% kbl(align = "c") %>% kable_styling(position = "center", font_size = 18) %>% kable_classic(lightable_options = "hover", html_font = "\"Source Sans Pro\", helvetica, sans-serif") 
```

# Concluding remarks{.smaller}
```{r}
# | fig-alt : "This hexagon is the R sticker for phase1b R package. It has a bright purple background, light orange border and the title is in fuschia. The graph in the middle is a CDF distribution in dots that changes from red dots to green dots to indicate a stop to go decision"
```
-   Big thank you to Daniel Sabanés Bové for mentorship. Data Science Acceleration
    colleagues Isaac Gravestock, John Kirkpatrick, Craig Gower-Paige et al who collaborated and supported.

-   Extension to other therapeutic areas that use response rate as
    endpoint if beta priors are appropriate.

# Questions and collaboration{background-iframe="lego-loader/dist/index.html"}

-   Open [issues
    here.](https://github.com/Genentech/phase1b/issues)\ Contact [me](audreytyeo@gmail.com) to collaborate. 

-   Next `phase1b` talk at the [Deutsche Arbeitsgemeinschaft Statistik 2025](https://dagstat2025.de/#) : Practical Bayesian Statistics : A gentle refresher on probability theory, Bayesian Framework and Intuition for effective application in Biostatistics

```{r, fig.align='left'}
#| layout-ncol: 5
#| fig-width: 1
#| fig-height: 3
knitr::include_graphics("images/hex3.png")
knitr::include_graphics("images/linkedin_qr.jpeg")
```

<!-- ![](images/hex3.png){width=20%} ![](images/linkedin_qr.jpeg){width=20%}  -->

# Some references

-   Thall P F, Simon R (1994), Practical Guidelines for Phase IIB
    Clinical Trials, Biometrics, 50, 337-349

-   Lee J J, Liu D D (2008), A Predictive probability design for phase
    II cancer clinical trials, 5(2), 93-106, Clinical Trials

-   Yeo, A T, Sabanés Bové D, Elze M, Pourmohamad T, Zhu J, Lymp J,
    Teterina A (2024). Phase1b : Calculations for decisions on Phase 1b
    clinical trials. R package version 1.0.0,
    <https://genentech.github.io/phase1b>
    
-   Inclusive Speaker Orientation [Linux Foundation](https://training.linuxfoundation.org/training/inclusive-speaker-orientation/)

# Some more references 

-   Zeileis, Fisher, Hornik, Ihaka, McWhite, Murrell, Stauffer, Wilke (2020). 
colorspace: A Toolbox for Manipulating and Assessing Colors and Palettes. Journal of Statistical Software.

-   [Code for this presentation](www.audreyyeCH.github.io/About)

# Backup slides

## Standard of Care Distribution when unknown
Using the approach by Thall and Simon (Biometrics, 1994), this evaluates the
posterior probability of achieving superior response rate in the treatment group `E`
compared to standard of care `S`. 

- The desired improvement is denoted as `delta`. There are two options in using `delta`.
The absolute case when `relativeDelta = FALSE` and relative as when `relativeDelta = TRUE`.


# Desired improvement `delta`, two approaches:{.smaller}

 1. The absolute case is when we define an absolute delta, greater than `P_S`,
the response rate of the standard of care or control or `S` group such that
the posterior is `Pr(P_E > P_S + delta | data)`.

 2. In the relative case, we suppose that the treatment group's
response rate is assumed to be greater than `P_S + (1-P_S) * delta` such that
the posterior is `Pr(P_E > P_S + (1 - P_S) * delta | data)`.

User facing functions with this feature include


- `postprobDist()`
- `predprobDist`
- `ocPostprobDist()`
- `ocPredprobDist()`
 
## Does CDF improve with increased "data availability" of priors ?

Here we have an interim result of 16 and 23 patients. (input for Likelihood)

We have a threshold of 60% success. Our standard of care is 60%. Our priors have a mean of 50%.

## Does CDF improve with increased "data availability" of priors ?

No.

```{r , fig.align='center'}
control = 0.6
thetaT_low = 0.6
thetaT_high = 0.9
result <- predprob(
  x = 16, n = 23, Nmax = 40, p = control, thetaT = thetaT_low,
  parE = c(10, 10)
)
result_parE_small <- predprob(
  x = 16, n = 23, Nmax = 40, p = control, thetaT = thetaT_low,
  parE = c(20, 20)
)
result_parE_medium <- predprob(
  x = 16, n = 23, Nmax = 40, p = control, thetaT = thetaT_low,
  parE = c(30, 30)
)
result_parE_large <- predprob(
  x = 16, n = 23, Nmax = 40, p = control, thetaT = thetaT_low,
  parE = c(40, 40)
)

data = rbind(result$table, result_parE_small$table, result_parE_medium$table, result_parE_large$table)

data$Category = c(rep("alpha = beta = 10", 18), rep("alpha = beta = 20", 18), rep("alpha = beta = 30", 18), rep("alpha = beta = 40", 18))

ggplot(data) +
  geom_point(aes(x = cumul_counts, y = posterior, colour = success, shape = Category), size = 1) +
  theme(legend.position = "right") +
  scale_x_continuous(breaks = seq(0, 40, by = 1)) +
  xlab("\nFuture successful reponders") +
  ylab("Probability\n") 
```

## Predictive posterior probability for Decision 1 :{.smaller} 


The criteria for Decision 1 for Interim looks are :

- interim GO : `P( success at final) > phiU`

- interim STOP : `P( success at final) < phiL`

The criteria for Decision 1 for Final looks are:

- Final GO : `P( response rate > p0 | data) > tT`

- Final STOP : `P( response rate > p0 | data ) < tT`

## Predictive posterior probability for Decision 2:{.smaller} 


The criteria for Decision 2 for Interim looks are :

- Interim GO : `P ( success at final) > phiU`

- Interim STOP : `P (failure at final ) > phiFu`

 The criteria for Decision 2 for Futility looks are :
 
 - Final GO : `P( response rate > p0) > tT`
 
 - Final STOP : `P( response rate  < p1) > tF`
 

